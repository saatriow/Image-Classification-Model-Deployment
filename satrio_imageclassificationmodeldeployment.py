# -*- coding: utf-8 -*-
"""satrio_ImageClassificationModelDeployment.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1o9XouzE0FxMBiCHGzD7L7DmJtSyY_1vO

Nama : M. Priambodo Satrio Wibowo

Email : satriow110702@gmail.com

Source : https://www.kaggle.com/datasets/muratkokludataset/rice-image-dataset

## Library
"""

# Commented out IPython magic to ensure Python compatibility.
import os, zipfile, shutil, PIL
import numpy as np
import tensorflow as tf
import matplotlib.image as mpimg
import matplotlib.pyplot as plt
# %matplotlib inline
from google.colab import files
from tensorflow import keras
from tensorflow.keras.utils import plot_model, to_categorical
from tensorflow.keras.models import Sequential
from tensorflow.keras.callbacks import EarlyStopping
from tensorflow.keras.optimizers import RMSprop
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense
from tensorflow.keras.preprocessing.image import ImageDataGenerator

"""## Path"""

!wget link_dataset \https://www.muratkoklu.com/datasets/vtdhnd09.php

"""## Dataset"""

local_zip = 'vtdhnd09.php'
zip_ref = zipfile.ZipFile(local_zip, 'r')
zip_ref.extractall('/tmp')
zip_ref.close()
base_dir = '/tmp/Rice_Image_Dataset'

os.listdir(base_dir)

os.remove("/tmp/Rice_Image_Dataset/Rice_Citation_Request.txt")
shutil.rmtree("/tmp/Rice_Image_Dataset/Karacadag")
shutil.rmtree("/tmp/Rice_Image_Dataset/Arborio")

os.listdir(base_dir)

def list_files(startpath):
  num_files = 0
  for root, dirs, files in os.walk(startpath):
    level = root.replace(startpath, '').count(os.sep)
    indent = ' ' * 2 * (level)
    num_files += len(files)
    print('{}{}/ {}'.format(indent, os.path.basename(root), (str(len(files)) + ' images' if len(files) > 0 else '')))

  return num_files

def read_files(startpath):
  image_files = []
  for dirname, dirnames, filenames in os.walk(startpath):
    for filename in filenames:
      image_files.append(os.path.join(dirname, filename))

  return image_files

full_dirs = read_files(base_dir)
image_sizes = []
for file in full_dirs:
  image = PIL.Image.open(file)
  width, height = image.size
  image_sizes.append(f'{width}x{height}')

unique_sizes = set(image_sizes)

print(f'Total Seluruh Gambar: {len(image_sizes)}')
print(f'Dengan Ukuran: {list(unique_sizes)[:10]}')

"""## Data Train dan Evaluasi"""

train_data = ImageDataGenerator(
    rescale = 1./255,
    rotation_range=20,
    width_shift_range=0.2,
    height_shift_range=0.2,
    brightness_range=(0.2,0.6),
    zoom_range=0.2,
    horizontal_flip=True,
    validation_split=0.2,
    fill_mode='nearest')

test_data = ImageDataGenerator(
    rescale=1./255,
    rotation_range=20,
    width_shift_range=0.2,
    height_shift_range=0.2,
    brightness_range=(0.2,0.6),
    zoom_range=0.2,
    horizontal_flip=True,
    validation_split=0.2,
    fill_mode='nearest')

train_gen = train_data.flow_from_directory(
    base_dir,
    target_size=(125, 125),
    class_mode='categorical',
    subset='training',
    shuffle=True
)

validation_gen= test_data.flow_from_directory(
    base_dir,
    target_size=(125,125),
    class_mode='categorical',
    subset='validation',
    shuffle=True
)

"""## Modelling"""

model = tf.keras.models.Sequential([tf.keras.layers.Conv2D(32,(3,3),activation = 'relu',input_shape = (125,125,3)),
                                    tf.keras.layers.MaxPooling2D(2,2),
                                    tf.keras.layers.Conv2D(64,(3,3),activation = 'relu'),
                                    tf.keras.layers.MaxPooling2D(2,2),
                                    tf.keras.layers.Conv2D(64,(3,3),activation = 'relu'),
                                    tf.keras.layers.MaxPooling2D(2,2),
                                    tf.keras.layers.Conv2D(128,(3,3),activation = 'relu'),
                                    tf.keras.layers.MaxPooling2D(2,2),
                                    tf.keras.layers.Conv2D(256,(3,3),activation = 'relu'),
                                    tf.keras.layers.MaxPooling2D(2,2),
                                    tf.keras.layers.Flatten(),
                                    tf.keras.layers.Dense(512,activation = 'relu'),
                                    tf.keras.layers.Dense(128,activation = 'relu'),
                                    tf.keras.layers.Dense(64,activation = 'relu'),
                                    tf.keras.layers.Dense(3,activation = 'softmax')
                                    ])
model.summary()

plot_model(
    model,
    show_shapes=True,
    show_layer_names=True,
)

"""## Callback"""

class myCallback(tf.keras.callbacks.Callback):
  def on_epoch_end(self, epoch, logs={}):
    if((logs.get('accuracy') > 0.85) and (logs.get('val_accuracy') > 0.85)):
      self.model.stop_training = True
      print("\naccuracy dari training set dan validation set mencapai > 85%!")
callbacks = myCallback()

"""## Training"""

LR = 1e-4
model.compile(loss='binary_crossentropy',
              optimizer=RMSprop(learning_rate=LR),
              metrics=['accuracy'])

result = model.fit(
    train_gen,
    validation_data=validation_gen,
    epochs=100,
    steps_per_epoch=50,
    validation_steps=35,
    callbacks=[callbacks],
    verbose=1
)

"""## Plot Akurasi dan Loss"""

plt.plot(result.history['accuracy'])
plt.plot(result.history['val_accuracy'])
plt.title('Akurasi Model')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['train', 'val'], loc = 'upper left')
plt.show()

plt.plot(result.history['loss'])
plt.plot(result.history['val_loss'])
plt.title('Loss Model')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train', 'val'], loc = 'upper left')
plt.show()

"""## TF-Lite"""

converter = tf.lite.TFLiteConverter.from_keras_model(model)
tfl_model = converter.convert()

with tf.io.gfile.GFile('Beras_Satrio.tflite', 'wb') as f:
  f.write(tfl_model)

